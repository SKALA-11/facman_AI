import os
import json
# import fitz # PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ì œ í•„ìš” ì—†ìŒ
import re
from langchain_core.documents import Document # langchain.schema ëŒ€ì‹  langchain_core.documents ì‚¬ìš©
from .chromadb_wrapper import ChromaDBWrapper # chromadb_wrapperëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
import logging

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO) # INFO ë ˆë²¨ ì´ìƒì˜ ë¡œê·¸ë¥¼ ì¶œë ¥

class JsonDataProcessor: # í´ë˜ìŠ¤ ì´ë¦„ì„ ì¢€ ë” ëª…í™•í•˜ê²Œ ë³€ê²½
    def __init__(
        self,
        json_data_path: str, # ì…ë ¥ JSON íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ
        chroma_dir: str = "./chroma_db_filtered", # ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        # output_json_path: str = "filtered_data_output.json" # í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œ (ì„ íƒì )
    ):
        self.json_data_path = json_data_path
        # self.output_json_path = output_json_path # ì´ ì˜ˆì œì—ì„œëŠ” í•„í„°ë§ í›„ ë³„ë„ ì €ì¥ ì•ˆ í•¨
        self.db = ChromaDBWrapper(persist_directory=chroma_dir) # ChromaDBWrapper ì‚¬ìš©
        self.data_for_chroma = [] # ChromaDBì— ì €ì¥í•  Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        self.keywords = ["ì•ˆì „", "ë³´ì•ˆ", "ìœ„í—˜", "ì¤€ìˆ˜", "ì¡°ì¹˜"] # í‚¤ì›Œë“œ í•„í„°ë§ì€ ìœ ì§€ (ì„ íƒ ì‚¬í•­)

    def clean_text(self, text: str) -> str:
        # ì¤„ë°”ê¿ˆê³¼ ì—°ì† ê³µë°± ì •ë¦¬
        text = re.sub(r"\s+", " ", text).strip()
        return text

    def filter_by_keywords(self, text: str) -> str:
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ í‚¤ì›Œë“œ í¬í•¨ ë¬¸ì¥ë§Œ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        # ë” ì •êµí•œ í•„í„°ë§ì´ í•„ìš”í•˜ë©´ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ê±°ë‚˜, í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¥/ë³€ê²½
        sentences = re.split(r"(?<=[.?!])\s+", text) # ë¬¸ì¥ ë¶„ë¦¬
        filtered_sentences = [
            sentence
            for sentence in sentences
            if any(keyword in sentence for keyword in self.keywords)
        ]
        # í•„í„°ë§ëœ ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¼ë„ ë°˜í™˜í•˜ê±°ë‚˜, ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ ê²°ì • í•„ìš”
        # ì—¬ê¸°ì„œëŠ” í•„í„°ë§ëœ ë¬¸ì¥ì´ ìˆìœ¼ë©´ í•©ì¹˜ê³ , ì—†ìœ¼ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì• 500ì ì •ë„ë¥¼ ì‚¬ìš© (ì˜ˆì‹œ)
        if filtered_sentences:
            return " ".join(filtered_sentences)
        # elif text: # í‚¤ì›Œë“œê°€ ì—†ë”ë¼ë„ ì¼ë¶€ ë‚´ìš©ì„ í¬í•¨ì‹œí‚¤ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ í•´ì œ
        #     logger.warning(f"í‚¤ì›Œë“œê°€ ì—†ì–´ ì›ë³¸ í…ìŠ¤íŠ¸ ì¼ë¶€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ (ì²« 500ì).")
        #     return text[:500] + "..." # ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ë¼ë„ ì‚¬ìš© (ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°)
        return "" # í‚¤ì›Œë“œ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (ì €ì¥ ì•ˆ í•¨)


    def process_json_file(self):
        logger.info(f"'{self.json_data_path}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
        try:
            with open(self.json_data_path, "r", encoding="utf-8") as f:
                loaded_json_data = json.load(f)
            
            if not isinstance(loaded_json_data, list):
                logger.error(f"'{self.json_data_path}' íŒŒì¼ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSONì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                return

            for item in loaded_json_data:
                if not isinstance(item, dict) or "file_name" not in item or "text" not in item:
                    logger.warning(f"JSON í•­ëª© í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ ê±´ë„ˆ<0xEB><0x8F><0xED><0x9E><0x88>ë‹ˆë‹¤: {item}")
                    continue

                file_name = item["file_name"]
                raw_text = item["text"]

                if raw_text:
                    # cleaned_text = self.clean_text(raw_text) # JSON í…ìŠ¤íŠ¸ëŠ” ì´ë¯¸ ì–´ëŠ ì •ë„ ì •ì œë˜ì—ˆì„ ìˆ˜ ìˆìŒ (í•„ìš”ì‹œ ì‚¬ìš©)
                    # filtered_text = self.filter_by_keywords(cleaned_text) # í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ì ìš©
                    
                    # ë°ëª¨ìš© ëª¨ì˜ ë°ì´í„°ëŠ” ì´ë¯¸ ì˜ ì •ì œë˜ì—ˆê³  íŠ¹ì • ëª©ì ì„ ê°€ì§€ë¯€ë¡œ,
                    # í‚¤ì›Œë“œ í•„í„°ë§ì„ ìƒëµí•˜ê³  ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    # ë§Œì•½ í‚¤ì›Œë“œ í•„í„°ë§ì„ ì›ì¹˜ ì•Šìœ¼ë©´ ë‹¤ìŒ ë¼ì¸ì„ ì‚¬ìš©:
                    processed_text = self.clean_text(raw_text) # ê°„ë‹¨í•œ í´ë¦¬ë‹ë§Œ ì ìš©
                    # ë˜ëŠ” í‚¤ì›Œë“œ í•„í„°ë§ì„ ê³„ì† ì‚¬ìš©í•˜ë ¤ë©´:
                    # processed_text = self.filter_by_keywords(self.clean_text(raw_text))

                    if processed_text:
                        # Langchain Document ê°ì²´ë¡œ ë³€í™˜
                        document = Document(
                            page_content=processed_text,
                            metadata={"file_name": file_name, "source": self.json_data_path} # ë©”íƒ€ë°ì´í„°ì— ì¶œì²˜ ì¶”ê°€
                        )
                        self.data_for_chroma.append(document)
                        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ (ChromaDB ì¶”ê°€ ì˜ˆì •): {file_name}")
                    else:
                        logger.info(f"ë‚´ìš©ì´ ì—†ê±°ë‚˜ í•„í„°ë§ë˜ì–´ ì œì™¸ëœ í•­ëª©: {file_name}")
                else:
                    logger.warning(f"'text' í•„ë“œê°€ ë¹„ì–´ìˆëŠ” í•­ëª©: {file_name}")

        except FileNotFoundError:
            logger.error(f"ğŸš« JSON ë°ì´í„° íŒŒì¼ '{self.json_data_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except json.JSONDecodeError:
            logger.error(f"ğŸš« JSON ë°ì´í„° íŒŒì¼ '{self.json_data_path}' íŒŒì‹± ì˜¤ë¥˜.")
        except Exception as e:
            logger.exception(f"JSON ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # def save_filtered_json(self): # í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ë¡œ ì €ì¥í•  ê²½ìš° ì‚¬ìš©
    #     if not self.data_for_chroma:
    #         logger.info("ì €ì¥í•  í•„í„°ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    #         return
    #     # Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    #     output_data = [{"file_name": doc.metadata.get("file_name"), "text": doc.page_content} for doc in self.data_for_chroma]
    #     with open(self.output_json_path, "w", encoding="utf-8") as f:
    #         json.dump(output_data, f, ensure_ascii=False, indent=4)
    #     logger.info(f"ğŸ’¾ í•„í„°ë§ëœ JSON ì €ì¥ ì™„ë£Œ: {self.output_json_path}")

    def save_to_chroma(self):
        if not self.data_for_chroma:
            logger.warning("ChromaDBì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"{len(self.data_for_chroma)}ê°œì˜ ë¬¸ì„œë¥¼ ChromaDBì— ì¶”ê°€í•©ë‹ˆë‹¤...")
        try:
            self.db.add_documents(self.data_for_chroma) # ChromaDBWrapperì˜ add_documents í˜¸ì¶œ
            logger.info(f"ğŸ’¾ Chroma DB ì €ì¥ ì™„ë£Œ. ì´ {len(self.data_for_chroma)}ê°œ ë¬¸ì„œ ì¶”ê°€ë¨. ìœ„ì¹˜: {self.db.persist_directory}")
        except Exception as e:
            logger.exception(f"ChromaDBì— ë¬¸ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    def run(self):
        logger.info("JsonDataProcessor ì‹¤í–‰ ì‹œì‘...")
        self.process_json_file() # JSON íŒŒì¼ ì²˜ë¦¬

        if self.data_for_chroma:
            # self.save_filtered_json() # í•„í„°ë§ëœ ê²°ê³¼ë¥¼ ë³„ë„ JSONìœ¼ë¡œ ì €ì¥í•  í•„ìš” ì—†ë‹¤ë©´ ì£¼ì„ ì²˜ë¦¬
            self.save_to_chroma() # ChromaDBì— ì €ì¥
        else:
            logger.info("ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ì–´ ChromaDBì— ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.info("JsonDataProcessor ì‹¤í–‰ ì™„ë£Œ.")


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    # ì´ ìŠ¤í¬ë¦½íŠ¸(factory_problem_data_collection.py)ëŠ” local_system/vector_db/ ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
    # filtered_data.jsonì€ local_system/gen_rand_events/ ì— ìˆìŠµë‹ˆë‹¤.
    # ê²½ë¡œë¥¼ ì •í™•íˆ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
    current_script_path = os.path.abspath(__file__) # factory_problem_data_collection.pyì˜ ì ˆëŒ€ ê²½ë¡œ
    vector_db_dir = os.path.dirname(current_script_path) # local_system/vector_db/
    local_system_root_dir = os.path.dirname(vector_db_dir) # local_system/
    project_root_dir = os.path.dirname(local_system_root_dir) # facman_AI/ (ê°€ì •)

    # ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
    json_input_file_path = os.path.join(local_system_root_dir, "gen_rand_events", "filtered_data.json")

    # ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì • (vector_db í´ë” ë‚´ì— ìƒì„±)
    chroma_database_dir = os.path.join(vector_db_dir, "chroma_db_from_json") # ìƒˆ ì´ë¦„ìœ¼ë¡œ ë³€ê²½ (ê¸°ì¡´ DBì™€ êµ¬ë¶„)
    
    # --- ì¤‘ìš”: ì´ì „ ChromaDB ë””ë ‰í† ë¦¬ ì‚­ì œ ---
    # ì„ë² ë”© ëª¨ë¸ì´ë‚˜ ë°ì´í„° ì†ŒìŠ¤ê°€ ë³€ê²½ë  ë•ŒëŠ” ì´ì „ DBë¥¼ ì‚­ì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” chroma_database_dirì„ ì‚¬ìš©í•˜ë¯€ë¡œ, ë§Œì•½ ì´ì „ì— ì´ ì´ë¦„ìœ¼ë¡œ DBê°€ ìˆì—ˆë‹¤ë©´ ì‚­ì œ.
    if os.path.exists(chroma_database_dir):
        import shutil
        logger.info(f"ê¸°ì¡´ ChromaDB ë””ë ‰í† ë¦¬ '{chroma_database_dir}'ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
        try:
            shutil.rmtree(chroma_database_dir)
        except Exception as e:
            logger.error(f"ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ '{chroma_database_dir}': {e}. ìˆ˜ë™ìœ¼ë¡œ ì‚­ì œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            exit() # ì‹¬ê°í•œ ì˜¤ë¥˜ ì‹œ ì¢…ë£Œ
    os.makedirs(chroma_database_dir, exist_ok=True) # ì‚­ì œ í›„ ë‹¤ì‹œ ìƒì„± (ë¹ˆ ë””ë ‰í† ë¦¬)
    # --- ì¤‘ìš”: ì´ì „ ChromaDB ë””ë ‰í† ë¦¬ ì‚­ì œ ë ---


    logger.info(f"ì…ë ¥ JSON íŒŒì¼ ê²½ë¡œ: {json_input_file_path}")
    logger.info(f"ChromaDB ì €ì¥ ê²½ë¡œ: {chroma_database_dir}")

    processor = JsonDataProcessor(
        json_data_path=json_input_file_path,
        chroma_dir=chroma_database_dir
    )
    processor.run()