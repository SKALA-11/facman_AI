import openai
import os
import json
from ..core.config import OPENAI_API_KEY, VECTOR_DB
from pathlib import Path
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.schema.output_parser import StrOutputParser
from langchain_core.messages import HumanMessage
from .prompts import get_solve_event_prompt, get_report_prompt

class ChatBot:
    def __init__(self):
        openai.api_key = OPENAI_API_KEY
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0.2, max_tokens=2048)
        self.solve_event_db = self.load_vector_store(VECTOR_DB)

    def load_vector_store(self, dir):
        return Chroma(persist_directory=dir, embedding_function=OpenAIEmbeddings())

    def solve_event(self, event, image, event_explain):
        try:
            print("\u2705 solve_event í˜¸ì¶œë¨")
            print("event:", event)
            print("image ê¸¸ì´:", len(image) if image else "ì—†ìŒ")
            print("event_explain:", event_explain)

            event_summary = f"[{event.type}] {event.time}: {event.value}"

            # Vector DB ê²€ìƒ‰
            rag = ""
            docs = self.solve_event_db.max_marginal_relevance_search(event_summary, k=5)
            if docs:
                rag += "\n".join([doc.page_content for doc in docs])

            # JSON ì°¸ê³ ìë£Œ ê¸°ë°˜ RAG ë³´ê°•
            try:
                base_path = Path(__file__).resolve().parent
                data_path = base_path.parent.parent / 'public' / 'src' / 'assets' / 'filtered_data.json'
                print("\ud83d\udcc4 json ê²½ë¡œ:", data_path)
                
                if not os.path.exists(data_path):
                    raise FileNotFoundError("filtered_data.json ê²½ë¡œì— íŒŒì¼ ì—†ìŒ")

                # ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ latin-1 ì‚¬ìš©
                with open(data_path, "r", encoding="latin-1") as f:
                    data = json.load(f)

                content = data["documents"][0]["text"]
                user_words = event_explain.split()
                sentences = content.split(". ")
                matched = [s for s in sentences if any(word in s for word in user_words)]
                if matched:
                    rag += "\n" + "\n".join([f"- {s.strip()}" for s in matched[:5]])
            except Exception as json_err:
                print("âš ï¸ JSON ë¶„ì„ ì¤‘ ì˜¤ë¥˜:", json_err)

            # ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ì „íˆ ë¶„ë¦¬
            if image and len(image) > 0:
                print("âœ… ì´ë¯¸ì§€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬")
                # ì§ì ‘ ë©”ì‹œì§€ êµ¬ì„±
                messages = [
                    {"role": "user", "content": [
                        {"type": "text", "text": f"ë‹¤ìŒ ì´ë²¤íŠ¸ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{event_explain}\n\nì°¸ê³ ìë£Œ: {rag}"},
                        {"type": "image_url", "image_url": {"url": image}}
                    ]}
                ]
                
                # OpenAI API ì§ì ‘ í˜¸ì¶œ
                try:
                    response = openai.chat.completions.create(
                        model="gpt-4o",
                        messages=messages,
                        temperature=0.2,
                        max_tokens=2048
                    )
                    answer = response.choices[0].message.content
                except Exception as img_err:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ API ì˜¤ë¥˜: {img_err}")
                    # ì´ë¯¸ì§€ ì˜¤ë¥˜ ì‹œ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                    text_only_prompt = f"ë‹¤ìŒ ì´ë²¤íŠ¸ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{event_explain}\n\nì°¸ê³ ìë£Œ: {rag}"
                    text_messages = [{"role": "user", "content": text_only_prompt}]
                    response = openai.chat.completions.create(
                        model="gpt-4o",
                        messages=text_messages,
                        temperature=0.2,
                        max_tokens=2048
                    )
                    answer = response.choices[0].message.content
            else:
                print("âœ… ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬")
                # í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                text_only_prompt = f"ë‹¤ìŒ ì´ë²¤íŠ¸ì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{event_explain}\n\nì°¸ê³ ìë£Œ: {rag}"
                text_messages = [{"role": "user", "content": text_only_prompt}]
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=text_messages,
                    temperature=0.2,
                    max_tokens=2048
                )
                answer = response.choices[0].message.content

            print("ğŸ§  GPT ì‘ë‹µ:", answer)
            return answer

        except Exception as e:
            import traceback
            traceback.print_exc()
            return f"[ERROR] solve_event ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}"

    def make_report_content(self, event, image, event_explain, answer):
        try:
            event_summary = f"[{event.type}] {event.time}: {event.value}"
            rag = ""
            docs = self.solve_event_db.max_marginal_relevance_search(event_summary, k=5)
            if docs:
                rag += "\n".join([doc.page_content for doc in docs])

            prompt = get_report_prompt(image, event_explain, rag, answer)
            chain = prompt | self.llm | StrOutputParser()

            report = chain.invoke({
                "image": image,
                "explain": event_explain,
                "rag": rag,
                "answer": answer
            })
            return report

        except Exception as e:
            import traceback
            traceback.print_exc()
            return f"[ERROR] make_report_content ì˜¤ë¥˜: {str(e)}"


# âœ… ì™¸ë¶€ì—ì„œ import ê°€ëŠ¥í•˜ë„ë¡ ì¸ìŠ¤í„´ìŠ¤í™”
chatbot = ChatBot()
